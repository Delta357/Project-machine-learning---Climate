library(dplyr)
pokemon <- read_csv("pokemon_data.csv")
head(pokemon)
library(readr)
library(dplyr)
pokemon <- read_csv("pokemon_data.csv")
head(pokemon)
head(pokemon)
tail(pokemon)
dim(pokemon)
pokemon <- pokemon_raw %>% select(6:11)
head(pokemon)
hist(data$Attack,
xlab = "Atack",
ylab = "Total",
title = "Atack dos pokemon")
hist(pokemon$Defense,
xlab = "Defesa",
ylab = "Total",
title = "Defesa dos pokemon")
boxplot(data$Attack,
xlab = "Atack",
ylab = "Total",
title = "Atack dos pokemon")
boxplot(pokemon$Defense,
xlab = "Defesa",
ylab = "Total",
title = "Defesa dos pokemon")
plot(pokemon$Attack)
wss <- 0
# Veja de 1 a 15 clusters possíveis
for (i in 1:15) {
# Ajuste o modelo: km.out
km.out <- kmeans(pokemon, centers = i, nstart = 20, iter.max = 50)
# Salve a soma dos quadrados dentro do cluster
wss[i] <- km.out$tot.withinss
}
# Produza um scree plot
plot(1:15, wss, type = "b",
xlab = "Número de clusters",
ylab = "Dentro de grupos soma de quadrados")
k <- 10
# Construir modelo com k clusters: km.out
km.pokemon <- kmeans(pokemon, centers = k, nstart = 20, iter.max = 50)
# Visualize o modelo resultante
km.pokemon
plot(pokemon[, c("Defense", "Speed")],
col = km.pokemon$cluster,
main = paste("Agrupamento de Pokémon com", k, "Clusters"),
xlab = "Defesa", ylab = "Velocidade")
# Ver os meios da coluna
colMeans(pokemon)
# Veja os desvios padrão da coluna
apply(pokemon, 2, sd)
# Dimensionar os dados
pokemon.scaled <- scale(pokemon)
# Crie um modelo de cluster hierárquico: hclust.pokemon
hclust.pokemon <- hclust(dist(pokemon.scaled), method = "complete")
# Aplique cutree() ao hclust.pokemon: cut.pokemon
cut.pokemon <- cutree(hclust.pokemon, k = 3)
# Comparar métodos
table(km.pokemon$cluster, cut.pokemon)
pokemon_pr <- data %>% select(HP, Attack, Defense, Speed)
glimpse(pokemon_pr)
summary(pokemon_pr)
pr.pokemon <- prcomp(x = pokemon_pr, scale = T, center = T)
summary
pr.pokemon
pr.pokemon$center
pr.pokemon$scale
pr.pokemon$rotation
head(pr.pokemon$x,10)
biplot(pr.pokemon)
# Variabilidade de cada componente principal: pr.var
pr.var <- pr.pokemon$sdev^2
# Variação explicada por cada componente principal: pve
pve <- pr.var / sum(pr.var)
pve
# Variação do gráfico explicada para cada componente principal
plot(pve, xlab = "Principal Component",
ylab = "Proportion of Variance Explained",
ylim = c(0, 1), type = "b")
plot(cumsum(pve), xlab = "Principal Component",
ylab = "Cumulative Proportion of Variance Explained",
ylim = c(0, 1), type = "b")
# Média de cada variável
colMeans(pokemon_pr)
# Desvio padrão de cada variável
apply(pokemon_pr, 2, sd)
# Modelo PCA com dimensionamento: pr.with.scaling
pr.with.scaling <- prcomp(pokemon_pr, scale = T, center = T)
# Modelo PCA sem dimensionamento: pr.without.scaling
pr.without.scaling <- prcomp(pokemon_pr, scale = F, center = F)
# Cria biplots de ambos para comparação
biplot(pr.without.scaling)
biplot(pr.with.scaling)
knit_with_parameters("G:/Meu Drive/Machine learning e deep learning/Cursos - Google Drive/Datacamp/Machine learning - R/Unsupervised Learning in R/Cap_02_Hierarchical_clustering/Projeto/kmeans_pokemon.Rmd", encoding = "UTF-8")
setwd("G:/Meu Drive/Machine learning e deep learning/Cursos - Google Drive/Datacamp/Machine learning - R/Unsupervised Learning in R/Cap_02_Hierarchical_clustering/Deploy")
library(readr)
library(dplyr)
pokemon <- read_csv("pokemon_data.csv")
head(pokemon)
head(pokemon)
tail(pokemon)
dim(pokemon)
pokemon <- pokemon_raw %>% select(6:11)
head(pokemon)
hist(data$Attack,
xlab = "Atack",
ylab = "Total",
title = "Atack dos pokemon")
hist(pokemon$Defense,
xlab = "Defesa",
ylab = "Total",
title = "Defesa dos pokemon")
boxplot(data$Attack,
xlab = "Atack",
ylab = "Total",
title = "Atack dos pokemon")
boxplot(pokemon$Defense,
xlab = "Defesa",
ylab = "Total",
title = "Defesa dos pokemon")
plot(pokemon$Attack)
wss <- 0
# Veja de 1 a 15 clusters possíveis
for (i in 1:15) {
# Ajuste o modelo: km.out
km.out <- kmeans(pokemon, centers = i, nstart = 20, iter.max = 50)
# Salve a soma dos quadrados dentro do cluster
wss[i] <- km.out$tot.withinss
}
# Produza um scree plot
plot(1:15, wss, type = "b",
xlab = "Número de clusters",
ylab = "Dentro de grupos soma de quadrados")
k <- 10
# Construir modelo com k clusters: km.out
km.pokemon <- kmeans(pokemon, centers = k, nstart = 20, iter.max = 50)
# Visualize o modelo resultante
km.pokemon
plot(pokemon[, c("Defense", "Speed")],
col = km.pokemon$cluster,
main = paste("Agrupamento de Pokémon com", k, "Clusters"),
xlab = "Defesa", ylab = "Velocidade")
# Ver os meios da coluna
colMeans(pokemon)
# Veja os desvios padrão da coluna
apply(pokemon, 2, sd)
# Dimensionar os dados
pokemon.scaled <- scale(pokemon)
# Crie um modelo de cluster hierárquico: hclust.pokemon
hclust.pokemon <- hclust(dist(pokemon.scaled), method = "complete")
# Aplique cutree() ao hclust.pokemon: cut.pokemon
cut.pokemon <- cutree(hclust.pokemon, k = 3)
# Comparar métodos
table(km.pokemon$cluster, cut.pokemon)
pokemon_pr <- data %>% select(HP, Attack, Defense, Speed)
glimpse(pokemon_pr)
summary(pokemon_pr)
pr.pokemon <- prcomp(x = pokemon_pr, scale = T, center = T)
summary
pr.pokemon
pr.pokemon$center
pr.pokemon$scale
pr.pokemon$rotation
head(pr.pokemon$x,10)
biplot(pr.pokemon)
# Variabilidade de cada componente principal: pr.var
pr.var <- pr.pokemon$sdev^2
# Variação explicada por cada componente principal: pve
pve <- pr.var / sum(pr.var)
pve
# Variação do gráfico explicada para cada componente principal
plot(pve, xlab = "Principal Component",
ylab = "Proportion of Variance Explained",
ylim = c(0, 1), type = "b")
plot(cumsum(pve), xlab = "Principal Component",
ylab = "Cumulative Proportion of Variance Explained",
ylim = c(0, 1), type = "b")
# Média de cada variável
colMeans(pokemon_pr)
# Desvio padrão de cada variável
apply(pokemon_pr, 2, sd)
# Modelo PCA com dimensionamento: pr.with.scaling
pr.with.scaling <- prcomp(pokemon_pr, scale = T, center = T)
# Modelo PCA sem dimensionamento: pr.without.scaling
pr.without.scaling <- prcomp(pokemon_pr, scale = F, center = F)
# Cria biplots de ambos para comparação
biplot(pr.without.scaling)
biplot(pr.with.scaling)
knit_with_parameters("G:/Meu Drive/Machine learning e deep learning/Cursos - Google Drive/Datacamp/Machine learning - R/Unsupervised Learning in R/Cap_02_Hierarchical_clustering/Deploy/notebook_kmeans.Rmd", encoding = "UTF-8")
unlink("notebook_kmeans_cache", recursive = TRUE)
setwd("G:/Meu Drive/Machine learning e deep learning/M.L Climate/Project-machine-learning---Climate/Notebook")
library(forecast)
install.packages("forecast")
#install.packages("forecast")
library(forecast)
library(ggplot2)
library(tseries)
library(summarytools)
install.packages("summarytools")
library(readr)
MER_T12_06 <- read_csv("Carbon Emissions/MER_T12_06.csv")
View(MER_T12_06)
#install.packages("summarytools")
library(forecast)
library(ggplot2)
library(tseries)
library(summarytools)
library(readr)
df <- read_csv("Carbon Emissions/MER_T12_06.csv")
library(readr)
df <- read_csv("MER_T12_06.csv")
head(df)
head(df)
dim(df)
class(df)
summary(df)
as.data.frame(df)
cycle(df)
as.data.frame(df)
plot(df,
ylab = "D", type="o")
plot(df,ylab = "D", type="Value")
plot(df)
plot(df$Value)
tsdata_decom <- decompose(df, type = "multiplicative")
library(xts)
tail(df)
gty2000<- subset(gt,(gt$yyyy<-substr((as.Date(gt$dt)),1,4)>=2000))
library(readr)
df <- read_csv("GlobalTemperatures.csv")
head(df)
as.data.frame(df)
#install.packages("summarytools")
library(forecast)
library(ggplot2)
library(tseries)
library(summarytools)
library(readr)
df <- read_csv("GlobalTemperatures.csv")
head(df)
tail(df)
head(df)
dim(df)
class(df)
summary(df)
as.data.frame(df)
str(df)
data_temp$df <- as.Date(data_temp$df, format="yyyy-mm-dd")
df$df <- as.Date(data_temp$df, format="yyyy-mm-dd")
df$df <- as.Date(df$df, format="yyyy-mm-dd")
temp_data$dt<-as.Date(temp_data$dt,format="yyyy-mm-dd")
temp_data$dt<-as.Date(temp_data$df,format="yyyy-mm-dd")
library(readr)
temp_data <- read_csv("GlobalTemperatures.csv")
head(temp_data)
temp_data$dt<-as.Date(temp_data$df,format="yyyy-mm-dd")
temp_data$dt<-as.Date(temp_data$dt,format="yyyy-mm-dd")
temp_data$dt<-as.Date(temp_data$dt,format="yyyy-mm-dd")
head(temp_data)
tail(temp_data)
options(repr.plot.width=4, repr.plot.height=4)
ggplot(temp_data,aes(x=LandAverageTemperature))+geom_histogram(aes(y=..density..),fill="blue")+geom_density(col="red")
options(repr.plot.width=5, repr.plot.height=5)
options(repr.plot.width=5, repr.plot.height=5)
temp_ts<-ts(temp_data[,2],start=c(1980,1),end=c(2015,12),frequency=12)
autoplot(temp_ts)
ggseasonplot(temp_ts)
ggseasonplot(temp_ts)
options(repr.plot.width=5, repr.plot.height=5)
temp_ts<-ts(temp_data[,2],start=c(1980,1),end=c(2015,12),frequency=12)
autoplot(temp_ts)
ggseasonplot(temp_ts,polar=TRUE)
ggsubseriesplot(temp_ts)
gglagplot(temp_ts)
gglagplot(temp_ts)
ggsubseriesplot(temp_ts)
ggAcf(temp_ts)
temp_fc<-snaive(temp_ts,h=36)
autoplot(temp_fc)
summary(temp_fc)
summary(temp_fc)
checkresiduals(temp_fc)
fit<-auto.arima(temp_ts,lambda=0)
d<-1
D<-1
fit %>%forecast(h=36)%>%autoplot()
checkresiduals(fit)
df$dt<-as.Date(df$dt,format="yyyy-mm-dd")
head(df)
tail(df)
model_fit <-auto.arima(temp,lambda = 0)
#install.packages("summarytools")
library(forecast)
library(ggplot2)
library(tseries)
library(summarytools)
library(readr)
df <- read_csv("GlobalTemperatures.csv")
head(df)
tail(df)
head(df)
dim(df)
class(df)
summary(df)
as.data.frame(df)
str(df)
df$dt<-as.Date(df$dt,format="yyyy-mm-dd")
head(df)
tail(df)
options(repr.plot.width=4, repr.plot.height=4)
ggplot(df,aes(x=LandAverageTemperature))+
geom_histogram(aes(y=..density..),fill="blue")+geom_density(col="red")
options(repr.plot.width=5, repr.plot.height=5)
temp <- ts(df[,2],start=c(1980,1),end=c(2015,12),frequency=12)
autoplot(temp)
ggseasonplot(temp)
ggseasonplot(temp, polar = TRUE)
ggsubseriesplot(temp)
gglagplot(temp)
ggAcf(temp)
temp<-snaive(temp,h = 36)
autoplot(temp)
summary(temp)
checkresiduals(temp)
model_fit <-auto.arima(temp,lambda = 0)
fit<-auto.arima(temp_ts,lambda=0)
d<-1
D<-1
fit %>%forecast(h=36)%>%autoplot()
checkresiduals(fit)
fit %>%forecast(h=36)%>%autoplot()
fit %>%forecast(h=36)%>%autoplot()
checkresiduals(model_fit)
model_fit<-auto.arima(temp_ts,lambda=0)
d<-1
D<-1
fit %>%forecast(h=36)%>%autoplot()
D<-1
model_fit<-auto.arima(temp_ts,lambda=0)
d<-1
D<-1
checkresiduals(model_fit)
model_fit<-auto.arima(temp_ts,lambda=0)
d<-1
D<-1
model_fit
summary(model_fit)
model_fit<-auto.arima(temp_ts,lambda=0)
d<-1
D<-1
model_fit<-auto.arima(temp_ts,lambda=0)
d<-1
D<-1
model_fit
# Carregando as bibliotecas
library(ggplot2)
library(scales)
library(dplyr)
library(readr)
library(data.table)
# Lendo o dataset
# Leando arquivo read_csv2()
system.time(data_1 <- read.csv("TemperaturasGlobais.csv"))
# Pacotes
install.packages("RSQLite")
library(RSQLite)
library(dplyr)
library(tidyr)
library(arules)
library(arulesSequences)
library(readr)
library(stringr)
library(visNetwork)
library(igraph)
library(lubridate)
library(DT)
# Conectando no banco de dados
con1 = dbConnect(RSQLite::SQLite(), dbname="database.sqlite")
con1
# Obtendo a lista de tabelas
alltables = dbListTables(con1)
alltables
# Extraindo as tabelas
players = dbReadTable(con1, "Player")
players_stats = dbReadTable(con, "Player_Attributes")
teams = dbReadTable(con, "Team")
league = dbReadTable(con, "League")
Matches = dbReadTable(con, "Match")
View(players)
View(players_stats)
View(teams)
View(league)
View(Matches)
library(googleVis)
install.packages("googleVis")
library(googleVis)
# Criando um Datafrane
df = data.frame(País = c("BR", "CH", "AR"),
Exportações = c(10,13,14),
Importações = c(23,12,32))
# Gráfico de Linha
Line <- gvisLineChart(df)
plot(Line)
print(paste('ARIMA(3,1,0) - AICc: ', round(fit$aicc,2)))
fit.test <- Arima(temp.global, order = c(3,1,1))
fit.test <- Arima(temp_ts, order = c(3,1,1))
print(paste('ARIMA(3,1,1) - AICc: ', round(fit.test$aicc,2)))
fit.test <- Arima(temp.global, order = c(3,1,2))
fit.test <- Arima(temp_ts, order = c(3,1,2))
print(paste('ARIMA(3,1,2) - AICc: ', round(fit.test$aicc,2)))
fit.test <- Arima(temp_ts, order = c(2,1,2))
print(paste('ARIMA(2,1,2) - AICc: ', round(fit.test$aicc,2)))
fit.auto <- auto.arima(temp_ts, seasonal = F)
summary(fit.auto)
Acf(residuals(fit.auto))
Btest <- Box.test(residuals(fit.auto),
lag = 10,
fitdf = 6,
type = "Ljung")
Btest
# pot forecast
temp.forecast <- forecast(fit.auto, h = 16)
plot(temp.forecast)
# plot test time series of the period 2001-2016
lines(ts(coredata(temp.global.test),
start = start(temp.forecast$mean)[1],
frequency = 1), col = 'magenta')
# plot test time series of the period 2001-2016
lines(ts(coredata(temp_ts),
start = start(temp.forecast$mean)[1],
frequency = 1), col = 'magenta')
# pot forecast
temp.forecast <- forecast(fit.auto, h = 16)
plot(temp.forecast)
# plot test time series of the period 2001-2016
lines(ts(coredata(temp_ts),
start = start(temp.forecast$mean)[1],
frequency = 1), col = 'magenta')
# pot forecast
temp.forecast <- forecast(fit.auto, h = 16)
plot(temp.forecast)
# plot test time series of the period 2001-2016
lines(temp_ts(coredata(temp_ts),
start = start(temp.forecast$mean)[1],
frequency = 1), col = 'magenta')
# pot forecast
temp.forecast <- forecast(fit.auto, h = 16)
plot(temp.forecast)
df_dff <- diff(df)
library(ggfortify)
library(gridExtra)
## ACF
p1 <- autoplot(Acf(df,
plot = F,
lag.max = 15)) + ggtitle('ACF')
df
ggsubseriesplot(temp)
#install.packages("summarytools")
library(forecast)
library(ggplot2)
library(tseries)
library(summarytools)
library(readr)
df <- read_csv("GlobalTemperatures.csv")
# Visualizando os 5 primeiros dados
head(df)
tail(df)
dim(df)
class(df)
summary(df)
as.data.frame(df)
str(df)
df$dt<-as.Date(df$dt,format="yyyy-mm-dd")
head(df)
tail(df)
options(repr.plot.width=4, repr.plot.height=4)
ggplot(df,aes(x=LandAverageTemperature))+
geom_histogram(aes(y=..density..),fill="blue")+geom_density(col="red")
options(repr.plot.width=5, repr.plot.height=5)
temp <- ts(df[,2],start=c(1980,1),end=c(2015,12),frequency=12)
autoplot(temp)
ggseasonplot(temp)
ggseasonplot(temp, polar = TRUE)
ggsubseriesplot(temp)
gglagplot(temp)
ggAcf(temp)
temp<-snaive(temp,h = 36)
autoplot(temp)
summary(temp)
checkresiduals(temp)
model_fit<-auto.arima(temp_ts,lambda=0)
d<-1
D<-1
model_fit
summary(model_fit)
fit %>%forecast(h=36)%>%autoplot()
checkresiduals(model_fit)
print(paste('ARIMA(3,1,0) - AICc: ', round(fit$aicc,2)))
fit.test <- Arima(temp_ts, order = c(3,1,1))
print(paste('ARIMA(3,1,1) - AICc: ', round(fit.test$aicc,2)))
fit.test <- Arima(temp_ts, order = c(3,1,2))
print(paste('ARIMA(3,1,2) - AICc: ', round(fit.test$aicc,2)))
fit.test <- Arima(temp_ts, order = c(2,1,2))
print(paste('ARIMA(2,1,2) - AICc: ', round(fit.test$aicc,2)))
fit.auto <- auto.arima(temp_ts, seasonal = F)
summary(fit.auto)
# pot forecast
temp.forecast <- forecast(fit.auto, h = 16)
plot(temp.forecast)
